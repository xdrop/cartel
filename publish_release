#!/usr/bin/env python
import hashlib
import subprocess
import requests
import os
import shutil
import zipfile
import re
import argparse
from datetime import datetime


# GitHub API configuration
GITHUB_API_URL = "https://api.github.com"
REPO_OWNER = "xdrop"
REPO_NAME = "cartel"
WORKFLOW_NAME = "Master Build"
GITHUB_TOKEN = os.environ.get("GITHUB_TOKEN")

# Setup headers for GitHub API requests
headers = {
    "Authorization": f"token {GITHUB_TOKEN}",
    "Accept": "application/vnd.github.v3+json",
}

# Define release directory
RELEASE_DIR = ".release"


def create_release_dir():
    """Create the release directory if it doesn't exist"""
    os.makedirs(RELEASE_DIR, exist_ok=True)
    return RELEASE_DIR


def get_workflow_id(workflow_name):
    """Get the workflow ID by name"""
    url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/actions/workflows"
    response = requests.get(url, headers=headers)
    response.raise_for_status()

    for workflow in response.json()["workflows"]:
        if workflow["name"] == workflow_name:
            return workflow["id"]

    raise ValueError(f"Workflow '{workflow_name}' not found")


def get_latest_run(workflow_id):
    """Get the latest workflow run"""
    url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/actions/workflows/{workflow_id}/runs"
    response = requests.get(url, headers=headers)
    response.raise_for_status()

    runs = response.json()["workflow_runs"]
    if not runs:
        raise ValueError("No workflow runs found")

    # Sort by created_at in descending order and get the first one
    latest_run = sorted(runs, key=lambda x: x["created_at"], reverse=True)[0]
    return latest_run


def get_artifacts(run_id):
    """Get artifacts for a workflow run"""
    url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/actions/runs/{run_id}/artifacts"
    response = requests.get(url, headers=headers)
    response.raise_for_status()

    return response.json()["artifacts"]


def download_artifact(artifact):
    """Download an artifact to the release directory"""
    artifacts_dir = os.path.join(RELEASE_DIR, "artifacts")
    os.makedirs(artifacts_dir, exist_ok=True)

    download_url = artifact["archive_download_url"]
    artifact_name = artifact["name"]
    output_path = os.path.join(artifacts_dir, f"{artifact_name}.zip")

    print(f"Downloading {artifact_name} to {output_path}...")

    response = requests.get(download_url, headers=headers, stream=True)
    response.raise_for_status()

    with open(output_path, "wb") as f:
        shutil.copyfileobj(response.raw, f)

    print(f"Successfully downloaded {artifact_name}")
    return output_path


def format_datetime(datetime_str):
    """Format datetime string to a more readable format"""
    dt = datetime.fromisoformat(datetime_str.replace("Z", "+00:00"))
    return dt.strftime("%Y-%m-%d %H:%M:%S UTC")


def extract_artifacts():
    """Extract all downloaded artifacts"""
    artifacts_dir = os.path.join(RELEASE_DIR, "artifacts")
    extract_dir = os.path.join(RELEASE_DIR, "extracted")
    os.makedirs(extract_dir, exist_ok=True)

    for filename in os.listdir(artifacts_dir):
        if filename.endswith(".zip"):
            file_path = os.path.join(artifacts_dir, filename)
            print(f"Extracting {filename}...")

            with zipfile.ZipFile(file_path, "r") as zip_ref:
                # Extract to a directory named after the artifact (without .zip)
                artifact_extract_dir = os.path.join(extract_dir, filename[:-4])
                os.makedirs(artifact_extract_dir, exist_ok=True)
                zip_ref.extractall(artifact_extract_dir)

            print(f"Extracted {filename} to {artifact_extract_dir}")


def package_by_platform():
    """Package artifacts by platform and architecture"""
    extract_dir = os.path.join(RELEASE_DIR, "extracted")
    output_dir = os.path.join(RELEASE_DIR, "releases")
    os.makedirs(output_dir, exist_ok=True)

    script_dir = os.path.dirname(os.path.abspath(__file__))
    launch_script_path = os.path.join(script_dir, "launch-daemon.sh")

    if not os.path.exists(launch_script_path):
        raise ValueError(f"Error: launch-daemon.sh not found at {launch_script_path}")

    # Pattern to extract version, platform, and architecture
    pattern = re.compile(
        r"(cartel|cartel-daemon)-(\d+\.\d+\.\d+(?:-[a-zA-Z0-9]+)?)\.(.*?)\.(.*?)$"
    )

    # Group artifacts by platform and architecture
    platform_artifacts = {}
    version = None

    for dirname in os.listdir(extract_dir):
        match = pattern.match(dirname)
        if match:
            program, artifact_version, platform, arch = match.groups()
            if version is None:
                version = artifact_version
            key = f"{platform}.{arch}"

            if key not in platform_artifacts:
                platform_artifacts[key] = {"version": artifact_version, "files": []}

            platform_artifacts[key]["files"].append(
                {
                    "program": program,
                    "full_path": os.path.join(extract_dir, dirname),
                }
            )

    # Create platform-specific zip files
    bundles = []
    for platform_key, data in platform_artifacts.items():
        output_filename = f"cartel-{version}.{platform_key}.zip"
        output_path = os.path.join(output_dir, output_filename)

        print(f"Creating platform bundle: {output_filename}")

        with zipfile.ZipFile(output_path, "w", zipfile.ZIP_DEFLATED) as zipf:
            for file_info in data["files"]:
                base_dir = file_info["full_path"]
                program = file_info["program"]

                # Add all files from the extracted directory to the zip
                for root, _, files in os.walk(base_dir):
                    for file in files:
                        file_path = os.path.join(root, file)
                        zipf.write(file_path, arcname=program)

            # Add launch-daemon.sh to each bundle if it exists
            if os.path.exists(launch_script_path):
                zipf.write(launch_script_path, arcname="launch-daemon.sh")

        print(f"Created {output_path}")
        bundles.append({"name": output_filename, "path": output_path})

    return version, bundles


def update_homebrew_formula(version, bundles):
    """Update the Homebrew formula with the new version and checksums"""
    print("\nUpdating Homebrew formula...")

    # Get the Homebrew tap repository
    brew_tap_dir = (
        subprocess.check_output(["brew", "--repository", "xdrop/homebrew-tap"])
        .decode()
        .strip()
    )
    formula_path = os.path.join(brew_tap_dir, "Formula/cartel.rb")

    # Find macOS bundles and extract their checksums
    arm64_bundle = None
    amd64_bundle = None

    for bundle in bundles:
        if "darwin.arm64" in bundle["name"]:
            arm64_bundle = bundle
        elif "darwin.amd64" in bundle["name"]:
            amd64_bundle = bundle

    if not arm64_bundle or not amd64_bundle:
        print("Error: Couldn't find both arm64 and x86_64 macOS bundles")
        return False

    # Calculate SHA256 checksums
    def calculate_sha256(filepath):
        with open(filepath, "rb") as f:
            return hashlib.sha256(f.read()).hexdigest()

    arm64_sha = calculate_sha256(arm64_bundle["path"])
    amd64_sha = calculate_sha256(amd64_bundle["path"])

    # Update the formula template with new version and checksums
    formula_content = f"""
    # this file was autogenerated by publish_release
    class Cartel < Formula
        version "{version}"
        desc "Local development orchestrator. Process & dependency management to run development playgrounds"
        homepage "https://github.com/xdrop/cartel"
        url "https://github.com/xdrop/cartel/releases/download/{version}/cartel-{version}.darwin.#{{Hardware::CPU.arm? ? "arm64" : "amd64"}}.zip"
        sha256 Hardware::CPU.arm? ? "{arm64_sha}" : "{amd64_sha}"
        license ""

        def install
            # Install both binaries to the bin directory
            bin.install "cartel"
            bin.install "cartel-daemon"
            prefix.install "launch-daemon.sh"
        end

        test do
            # Test that the binaries exist and are executable
            system bin/"cartel", "--version"
            system bin/"cartel-daemon", "--version"
        end

        def caveats
            <<~EOS
            Add the following line to your ~/.bash_profile or ~/.zshrc file:
                [ -f #{{opt_prefix}}/launch-daemon.sh ] && . #{{opt_prefix}}/launch-daemon.sh
            Restart your terminal for the settings to take effect.
            EOS
        end
    end
    """

    # Format the formula content with proper indentation
    formatted_formula = "\n".join(
        line.removeprefix("    ") for line in formula_content.split("\n")
    )

    # Write the updated formula to the file
    with open(formula_path, "w") as f:
        f.write(formatted_formula)

    # Stage, commit, and push the changes to the Homebrew tap
    os.chdir(brew_tap_dir)
    subprocess.run(["git", "add", formula_path])
    subprocess.run(["git", "commit", "-m", f"Bump cartel to {version}"])
    # subprocess.run(["git", "push"])

    print(f"Updated Homebrew formula to version {version}")
    return True


def create_github_release(version, bundles):
    """Create a GitHub release and upload assets"""
    release_name = f"{version}"

    print(f"\nCreating GitHub release: {release_name}")

    create_url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/releases"
    release_data = {
        "tag_name": version,
        "name": release_name,
        "draft": False,
        "prerelease": False,
    }

    response = requests.post(create_url, headers=headers, json=release_data)
    response.raise_for_status()

    release = response.json()
    release_id = release["id"]
    print(f"Created release with ID: {release_id}")

    # Upload each bundle as an asset
    for bundle in bundles:
        bundle_name = bundle["name"]
        bundle_path = bundle["path"]

        print(f"Uploading bundle: {bundle_name}")

        upload_url = release["upload_url"].replace("{?name,label}", "")
        with open(bundle_path, "rb") as file:
            upload_headers = headers.copy()
            upload_headers["Content-Type"] = "application/zip"
            params = {"name": bundle_name}

            upload_response = requests.post(
                upload_url, headers=upload_headers, params=params, data=file
            )
            upload_response.raise_for_status()

        print(f"Successfully uploaded {bundle_name}")

    print(f"\nRelease created successfully: {release['html_url']}")
    return release


def get_already_packaged_release():
    """Get the already packaged release"""
    output_dir = os.path.join(RELEASE_DIR, "releases")
    bundles = []
    version = None

    for filename in os.listdir(output_dir):
        if filename.endswith(".zip"):
            match = re.match(
                r"cartel-(\d+\.\d+\.\d+(?:-[a-zA-Z0-9]+)?).(.+).zip", filename
            )
            if match:
                version = match.group(1)
                bundles.append(
                    {"name": filename, "path": os.path.join(output_dir, filename)}
                )

    return version, bundles


def parse_args():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(description="Process and publish GitHub releases")
    parser.add_argument(
        "--build",
        type=lambda x: str(x).lower() not in ["0", "false", "no"],
        default=True,
        help="Build the release (use --build=false or --build=0 or --build=no to disable)",
    )
    parser.add_argument(
        "--release",
        action="store_true",
        help="Publish the release to GitHub (if not set, only prepares the release files)",
    )
    parser.add_argument(
        "--release-brew",
        action="store_true",
        help="Publish the release to Homebrew",
    )
    return parser.parse_args()


def main():
    args = parse_args()

    if not GITHUB_TOKEN:
        print("Error: GITHUB_TOKEN environment variable not set.")
        print("Please set your GitHub token as an environment variable.")
        return

    try:
        if args.build:
            # Create release directory
            create_release_dir()
            print(f"Building release in directory: {RELEASE_DIR}")

            # Get workflow ID
            workflow_id = get_workflow_id(WORKFLOW_NAME)
            print(f"Found workflow: {WORKFLOW_NAME} (ID: {workflow_id})")

            # Get latest run
            latest_run = get_latest_run(workflow_id)
            run_id = latest_run["id"]

            # fmt: off
            print(f"\nLatest run details:")
            print(f"  Run ID: {run_id}")
            print(f"  Status: {latest_run['status']}, Conclusion: {latest_run['conclusion']}")
            print(f"  Created at: {format_datetime(latest_run['created_at'])}")
            print(f"  URL: {latest_run['html_url']}")
            # fmt: on

            # Get artifacts for the run
            artifacts = get_artifacts(run_id)

            print(f"\nArtifacts ({len(artifacts)}):")
            for i, artifact in enumerate(artifacts, 1):
                # fmt: off
                print(f"  {i}. {artifact['name']} ({artifact['size_in_bytes']} bytes)")
                print(f"     Created: {format_datetime(artifact['created_at'])}")
                print(f"     Expires: {format_datetime(artifact['expires_at'])}")
                print(f"     Download URL: {artifact['archive_download_url']}")
                # fmt: on
                print()

            if artifacts:
                print("Downloading all artifacts...")
                for artifact in artifacts:
                    download_artifact(artifact)
                print("All artifacts downloaded successfully!")
            else:
                print("Error: No artifacts found to download.")
                exit(1)

            # Extract downloaded artifacts
            print("\nExtracting artifacts...")
            extract_artifacts()

            # Repackage by platform and architecture
            print("\nRepackaging by platform and architecture...")
            version, bundles = package_by_platform()

            if not version:
                print("Error: Could not determine release version from artifacts.")
                return
        else:
            print("Skipping build step. Using already packaged release...")
            version, bundles = get_already_packaged_release()

        # Only publish the release if --release flag is set
        if args.release:
            print(f"\nCreating GitHub release for version {version}...")
            create_github_release(version, bundles)
            print("\nRelease published successfully!")
        else:
            print(f"\nRelease files prepared for version {version} but not published.")
            print("Use --release flag to publish to GitHub.")

        if args.release_brew:
            if update_homebrew_formula(version, bundles):
                print("\nHomebrew formula updated successfully!")
            else:
                print("\nError updating Homebrew formula")

        print("\nProcess completed successfully!")

    except Exception as e:
        print(f"Error: {e}")


if __name__ == "__main__":
    main()
